

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>KQLearning &mdash; CodPy Book 1.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css?v=1277b6f3" />
      <link rel="stylesheet" type="text/css" href="_static/custom.css" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=8d563738"></script>
      <script src="_static/doctools.js?v=9a2dae69"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script>let toggleHintShow = 'Click to show';</script>
      <script>let toggleHintHide = 'Click to hide';</script>
      <script>let toggleOpenOnPrint = 'true';</script>
      <script src="_static/togglebutton.js?v=4a39c7ea"></script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "displayMath": [["$$", "$$"], ["\\[", "\\]"]]}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Chapter 8: Reinforcement learning." href="auto_ch8/index.html" />
    <link rel="prev" title="7.06 Automatic Differentiation" href="auto_ch7/ch7_AAD.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            CodPy Book
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Chapter 2:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="auto_ch2/index.html">Chapter 2: Basic notions on reproducing kernels</a><ul>
<li class="toctree-l2"><a class="reference internal" href="auto_ch2/ch2_2.html">2.2 Reproducing kernels and transformation maps</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch2/ch2_ex1D.html">2.3 1D Periodic Function Extrapolation</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch2/ch2_5.html">2.3.2 Applying maps to kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch2/ch2_ex2D.html">2.4 2D Periodic Function Extrapolation</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch2/ch2_discrepancy_functional.html">2.6.2 A study of the discrepancy functional</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapter 3:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="auto_ch3/index.html">Chapter 3: Discrete operators based on reproducing kernels</a><ul>
<li class="toctree-l2"><a class="reference internal" href="auto_ch3/ch3_3_2.html">3.3.2 Partition of unity</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch3/ch3_4_1.html">3.4.1 Gradient Operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch3/ch3_4_2.html">3.4.2 Divergence Operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch3/ch3_4_3.html">3.4.3  Inverse Laplace operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch3/ch3_4_4.html">3.4.4 Integral operator - inverse gradient operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch3/ch3_4_5.html">3.4.5  Integral operator - inverse divergence operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch3/ch3_4_6.html">3.4.6 Leray-orthogonal operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch3/ch3_4_7.html">3.4.7 Leray operator and Helmholtz-Hodge decomposition</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapter 4:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="auto_ch4/index.html">Chapter 4: Clustering strategies</a><ul>
<li class="toctree-l2"><a class="reference internal" href="auto_ch4/ch4_2.html">4.2 Clustering</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapter 5:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="auto_ch5/index.html">Chapter 5: Optimal transport and statistical kernel methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="auto_ch5/ch5_2.html">5.2 Optimal Transport: LSAP (Linear Sum Assignment Problem)</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch5/ch5_33.html">5.3.3 Kernel Conditional Density</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch5/ch5_34.html">5.3.4 Kernel Conditional Expectation</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch5/ch5_6_a.html">5.6.a Application of OT in Disitribution Sampling : 1D</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch5/ch5_6_b.html">5.6.b Application of OT in Disitribution Sampling : 2D</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch5/ch5_6_c.html">5.6.c Application of OT in Disitribution Sampling : High-Dimensional case</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch5/ch5_6_d.html">5.6.d Exploration Data Analysis of the Latent Space: Spherical Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch5/ch5_7.html">5.7. Conditional Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch5/ch5_8.html">5.8. Conditional Sampling</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapter 6:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="auto_ch6/index.html">Chapter 6: Applications to machine learning : supervised, unsupervised and generative methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="auto_ch6/ch6_housing.html">6.1 Supervised learning: reproducibility illustration with housing prices</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch6/ch6_mnist.html">6.2 Supervised learning: benchmarks of methods with MNIST</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch6/ch6_Clustering.html">6.3 Unsupervised learning: Clustering - MNIST</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch6/ch6_ClustMNIST.html">6.3 Unsupervised learning: Clustering - MNIST</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch6/ch6_CreditCardFraud.html">6.4 Unsupervised learning: Clustering - Fraud detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch6/ch6_9_CelebA_reconstruction.html">6.4.1 Generating complex distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch6/ch6_9_CelebA.html">6.4.1 Generating complex distributions from celebA dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch6/ch6_9_transfert.html">6.4.5 Conditioning on discrete distributions of celebA dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch6/ch6_stockClustering.html">6.5 Unsupervised learning: Clustering - Stock Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch6/ch6_iris.html">6.7. Conditional Sampling</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapter 7:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="auto_ch7/index.html">Chapter 7: Application to partial differential equations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="auto_ch7/ch7_invLaplace.html">7.01 Inverse Laplace Operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch7/ch7_denoising.html">7.02 Denoising</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch7/ch7_heat_eq.html">7.03 Heat Equation</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch7/ch7_heatLagrange.html">7.04 Lagrange Heat Equation</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch7/ch7_convexHull.html">7.05 Convex Hull Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch7/ch7_AAD.html">7.06 Automatic Differentiation</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapter 8:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">KQLearning</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_ch8/index.html">Chapter 8: Reinforcement learning.</a><ul>
<li class="toctree-l2"><a class="reference internal" href="auto_ch8/ch8_example.html">8.1 Using KAgents</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch8/ch8_cartpole.html">8.2 Experiments - Cartpole</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch8/ch8_lunarlander.html">8.3 Experiments - LunarLander</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Chapter 9:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="auto_ch9/index.html">Chapter 9: Mathematical Finance.</a><ul>
<li class="toctree-l2"><a class="reference internal" href="auto_ch9/ch9_get_market_data.html">9.01 Free time series modeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch9/ch9_random_walk_log_normal.html">9.02 Random walks</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch9/ch9_arma.html">9.03 ARMA(p,1) model</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch9/ch9_garch.html">9.04 GARCH(1,1) model</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch9/ch9_lagrange.html">9.05 Lagrange interpolation model</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch9/ch9_additive.html">9.06 Additive noise map</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch9/ch9_conditionning.html">9.07 Conditionning model</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch9/ch9_stoch_vol.html">9.08 Stochastic volatility model</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch9/ch9_HestonCompare.html">9.10 Heston Process - Path comparison</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch9/ch9_isocontours.html">9.11 Heston Process - Intraday interpolation</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch9/ch9_priceExtrapolation.html">9.12 Price extrapolation using KRR and Taylor</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch9/ch9_greeks.html">9.13 Greeks output after correction</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch9/ch9_rst.html">9.13 Reverse Stress Test</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_ch9/ch9_HestonRepro.html">9.9 Heston Process - Reproducibility</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="utils/ch9/ch9_utils.html">Chapter 9 utility functions</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">CodPy Book</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">KQLearning</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/kqlearning.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-codpy.KQLearning">
<span id="kqlearning"></span><h1>KQLearning<a class="headerlink" href="#module-codpy.KQLearning" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="codpy.KQLearning.GamesKernel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">codpy.KQLearning.</span></span><span class="sig-name descname"><span class="pre">GamesKernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_distribution</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">next_states</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#GamesKernel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.GamesKernel" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Kernel</span></code></p>
<p>A specific type of kernel for deterministic policies, handling clustering</p>
<p>Initializes the Kernel class with default or user-defined parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – A bi-dimensional numpy array.</p></li>
<li><p><strong>fx</strong> – A bi-dimensional numpy array. If <cite>x</cite> or <cite>fx</cite> is not <cite>None</cite>, then call <code class="xref py py-func docutils literal notranslate"><span class="pre">set()</span></code></p></li>
<li><p><strong>max_nystrom</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, optional) – Maximum number of Nystrom samples. Defaults to 1000.</p></li>
<li><p><strong>reg</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, optional) – Regularization parameter for kernel operations. Defaults to 1e-9.</p></li>
<li><p><strong>order</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, optional, order of the polynomial kernel) – Polynomial order for polynomial kernel functions. Defaults to <code class="docutils literal notranslate"><span class="pre">None</span></code> (no polynomial regression).</p></li>
<li><p><strong>dim</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, optional) – Dimensionality of the input data. Defaults to 1.</p></li>
<li><p><strong>set_kernel</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">callable</span></code>, optional) – A custom kernel function initializer. If not provided, defaults to <code class="docutils literal notranslate"><span class="pre">self.default_clustering_functor()</span></code>.</p></li>
<li><p><strong>kwargs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>) – Additional keyword arguments for further customization.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="codpy.KQLearning.GamesKernelClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">codpy.KQLearning.</span></span><span class="sig-name descname"><span class="pre">GamesKernelClassifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#GamesKernelClassifier"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.GamesKernelClassifier" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#codpy.KQLearning.GamesKernel" title="codpy.KQLearning.GamesKernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">GamesKernel</span></code></a></p>
<p>A specific type of kernel for stochastic policies. Outputs probabilities</p>
<p>Initializes the Kernel class with default or user-defined parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – A bi-dimensional numpy array.</p></li>
<li><p><strong>fx</strong> – A bi-dimensional numpy array. If <cite>x</cite> or <cite>fx</cite> is not <cite>None</cite>, then call <code class="xref py py-func docutils literal notranslate"><span class="pre">set()</span></code></p></li>
<li><p><strong>max_nystrom</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, optional) – Maximum number of Nystrom samples. Defaults to 1000.</p></li>
<li><p><strong>reg</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>, optional) – Regularization parameter for kernel operations. Defaults to 1e-9.</p></li>
<li><p><strong>order</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, optional, order of the polynomial kernel) – Polynomial order for polynomial kernel functions. Defaults to <code class="docutils literal notranslate"><span class="pre">None</span></code> (no polynomial regression).</p></li>
<li><p><strong>dim</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, optional) – Dimensionality of the input data. Defaults to 1.</p></li>
<li><p><strong>set_kernel</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">callable</span></code>, optional) – A custom kernel function initializer. If not provided, defaults to <code class="docutils literal notranslate"><span class="pre">self.default_clustering_functor()</span></code>.</p></li>
<li><p><strong>kwargs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>) – Additional keyword arguments for further customization.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="codpy.KQLearning.rl_hot_encoder">
<span class="sig-prename descclassname"><span class="pre">codpy.KQLearning.</span></span><span class="sig-name descname"><span class="pre">rl_hot_encoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">actions_dim</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#rl_hot_encoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.rl_hot_encoder" title="Link to this definition"></a></dt>
<dd><p>Hot encodes actions over actions_dim.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>actions</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">np.ndarray</span></code>.</p></li>
<li><p><strong>actions_dim</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> The dimension of the actions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">pd.DataFrame</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="codpy.KQLearning.KAgent">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">codpy.KQLearning.</span></span><span class="sig-name descname"><span class="pre">KAgent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma=0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_type=&lt;class</span> <span class="pre">'codpy.KQLearning.GamesKernel'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#KAgent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.KAgent" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Basic KAgent. Has most of the usefull methods for other Reinforcement Learning algorithms.</p>
<p>Initializes the KAgent with the given parameters. Every agent has an actor and critic kernel. Some classes might not use both.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>actions_dim</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> The action dimension of the environment.</p></li>
<li><p><strong>state_dim</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> The state dimension of the environment.</p></li>
<li><p><strong>gamma</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> Discount factor.</p></li>
<li><p><strong>kernel_type</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">codpy.kernel.Kernel</span></code> Type of kernel to be used as actor and critic.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="codpy.KQLearning.KAgent.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma=0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_type=&lt;class</span> <span class="pre">'codpy.KQLearning.GamesKernel'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#KAgent.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.KAgent.__init__" title="Link to this definition"></a></dt>
<dd><p>Initializes the KAgent with the given parameters. Every agent has an actor and critic kernel. Some classes might not use both.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>actions_dim</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> The action dimension of the environment.</p></li>
<li><p><strong>state_dim</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> The state dimension of the environment.</p></li>
<li><p><strong>gamma</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> Discount factor.</p></li>
<li><p><strong>kernel_type</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">codpy.kernel.Kernel</span></code> Type of kernel to be used as actor and critic.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="codpy.KQLearning.KAgent.compute_returns">
<span class="sig-name descname"><span class="pre">compute_returns</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">states</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">next_states</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rewards</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dones</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#KAgent.compute_returns"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.KAgent.compute_returns" title="Link to this definition"></a></dt>
<dd><p>Computes <span class="math notranslate nohighlight">\(G_t = R_t + \gamma G_{t+1}\)</span> for the given history.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>states</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">np.ndarray</span></code> The states of the game, in reverse order.</p></li>
<li><p><strong>actions</strong></p></li>
<li><p><strong>next_states</strong></p></li>
<li><p><strong>rewards</strong></p></li>
<li><p><strong>dones</strong></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">np.ndarray</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="codpy.KQLearning.KAgent.bellman_optimal_action">
<span class="sig-name descname"><span class="pre">bellman_optimal_action</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">games</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">q_value_function</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#KAgent.bellman_optimal_action"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.KAgent.bellman_optimal_action" title="Link to this definition"></a></dt>
<dd><p>Computes the optimal actions for the given <span class="math notranslate nohighlight">\(Q(s,a)\)</span> function, with <div class="math notranslate nohighlight">
\[Q^*(s,a) = R(s,a) + \gamma \max_{a'} Q^{\pi}(s',a')\]</div>
.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>games</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code> SARSD in reverse order.</p></li>
<li><p><strong>q_value_function</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">codpy.kernel.Kernel</span></code> The Q-value function.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">np.ndarray</span></code> The optimal actions one hot encoded.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="codpy.KQLearning.KAgent.update_probabilities">
<span class="sig-name descname"><span class="pre">update_probabilities</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">advantages</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">games</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_policy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#KAgent.update_probabilities"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.KAgent.update_probabilities" title="Link to this definition"></a></dt>
<dd><p>Updates the policies for advantage-based algorithms. The advantage either is <span class="math notranslate nohighlight">\(\nabla_{y} Q^\pi_k(\cdot)\)</span> for Policy Gradient methods, or <span class="math notranslate nohighlight">\(R(s,a) + \gamma V^{\pi}(s') - V^{\pi}(s)\)</span> for ActorCritic.</p>
<p>It does normalize the advantages and then computes the new policy as an interpolation between the last policy and the new one.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>advantages</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">np.ndarray</span></code></p></li>
<li><p><strong>games</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code> SARSD in reverse order.</p></li>
<li><p><strong>last_policy</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">np.ndarray</span></code> The last policy.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">codpy.kernel.Kernel</span></code> The new policy.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="codpy.KQLearning.KAgent.get_derivatives_policy_state_action_value_function">
<span class="sig-name descname"><span class="pre">get_derivatives_policy_state_action_value_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">games</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_value_function</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#KAgent.get_derivatives_policy_state_action_value_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.KAgent.get_derivatives_policy_state_action_value_function" title="Link to this definition"></a></dt>
<dd><p>Solve for <div class="math notranslate nohighlight">
\[\nabla_{y} \theta^\pi = \gamma \Big(K(Z,Z) - \gamma \sum_a \pi^a(S) K(W,Z) \Big)^{-1} \sum_a\Big(Q^{\pi}_k(W) \pi^a(\delta_b(a)-\pi^b)\Big)\]</div>
</p>
<p>Where:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Z\)</span> are the state actions</p></li>
<li><p><span class="math notranslate nohighlight">\(W\)</span> are the next state actions</p></li>
<li><p><span class="math notranslate nohighlight">\(K(Z,Z)\)</span> is the Gram matrix of the training points</p></li>
<li><p><span class="math notranslate nohighlight">\(\gamma \sum_a \pi^a(S) K(W,Z)\)</span> is the weighted projection operator onto the next state-actions</p></li>
<li><p><span class="math notranslate nohighlight">\(Q^{\pi}_k(W)\)</span> is the critic evaluated at the next state-actions</p></li>
<li><p><span class="math notranslate nohighlight">\(\pi^a(\delta_b(a)-\pi^b)\)</span> is an adjustment based on probability differences</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>games</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code> SARSD in reverse order.</p></li>
<li><p><strong>policy</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">np.ndarray</span></code> The policy to be used for weigthing the next state-actions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">codpy.kernel.Kernel</span></code> The derivative estimator of <span class="math notranslate nohighlight">\(Q(s,a)\)</span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="codpy.KQLearning.KAgent.optimal_states_values_function">
<span class="sig-name descname"><span class="pre">optimal_states_values_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">games</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_output</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#KAgent.optimal_states_values_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.KAgent.optimal_states_values_function" title="Link to this definition"></a></dt>
<dd><p>Find a kernel regressor solving the Bellman equation  <div class="math notranslate nohighlight">
\[Q(s,a) = r + \gamma \max_{a'} Q(s',a')\]</div>

The algorithm computes <span class="math notranslate nohighlight">\(Q^n(s,a)\)</span> iteratively :</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Solve <span class="math notranslate nohighlight">\(\theta^{\pi}_{n+1/2} = \Big( K(Z, Z) - \gamma \sum_a \pi_{n+1/2}^a(S) K(W^a,Z)\Big)^{-1} R\)</span></p></li>
<li><p>Refines the parameters <span class="math notranslate nohighlight">\(\theta_{n+1}^{\pi} = \lambda \theta^{\pi}_{n+1/2} + (1 - \lambda) \theta_{n}^{\pi}.\)</span></p></li>
</ol>
</div></blockquote>
<dl class="simple">
<dt>Where:</dt><dd><ul class="simple">
<li><p>Z is the concatenation of the states and actions</p></li>
<li><p><span class="math notranslate nohighlight">\(K(Z,Z)\)</span> is the gram matrix of current state actions pairs</p></li>
<li><p><span class="math notranslate nohighlight">\(K(W^a,Z)\)</span> is the gram matrix of the next states and actions</p></li>
<li><p><span class="math notranslate nohighlight">\(\pi_{n+1/2}^a(S) = \delta_{\arg \max q^n(S,a) }(S)\)</span> is the max of the next Q-values, with <span class="math notranslate nohighlight">\(q^n\)</span> the current Q-values.</p></li>
<li><p><span class="math notranslate nohighlight">\(R\)</span> is the rewards function</p></li>
</ul>
</dd>
</dl>
<p>The function then assures a limit condition on the Q-values by setting the last Q-values equal to the rewards.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>games</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code> SARSD in reverse order.</p></li>
<li><p><strong>kernel</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">codpy.kernel.Kernel</span></code> Kernel to be used. If None, a kernel fit on the returns is used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">codpy.kernel.Kernel</span></code> The kernel with the optimal Q-values.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="codpy.KQLearning.KActorCritic">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">codpy.KQLearning.</span></span><span class="sig-name descname"><span class="pre">KActorCritic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma=0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_type=&lt;class</span> <span class="pre">'codpy.KQLearning.GamesKernel'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#KActorCritic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.KActorCritic" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#codpy.KQLearning.KAgent" title="codpy.KQLearning.KAgent"><code class="xref py py-class docutils literal notranslate"><span class="pre">KAgent</span></code></a></p>
<p>KActorCritic Kernel algorithm. It is policy-based and uses a <a class="reference internal" href="#codpy.KQLearning.GamesKernelClassifier" title="codpy.KQLearning.GamesKernelClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">GamesKernelClassifier</span></code></a> as the actor.</p>
<p>Initializes the KAgent with the given parameters. Every agent has an actor and critic kernel. Some classes might not use both.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>actions_dim</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> The action dimension of the environment.</p></li>
<li><p><strong>state_dim</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> The state dimension of the environment.</p></li>
<li><p><strong>gamma</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> Discount factor.</p></li>
<li><p><strong>kernel_type</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">codpy.kernel.Kernel</span></code> Type of kernel to be used as actor and critic.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="codpy.KQLearning.KActorCritic.get_advantages">
<span class="sig-name descname"><span class="pre">get_advantages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">games</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#KActorCritic.get_advantages"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.KActorCritic.get_advantages" title="Link to this definition"></a></dt>
<dd><p>Compute the advantage function <div class="math notranslate nohighlight">
\[A^{\pi^a}(s) = R(s,a) + \gamma V^{\pi}(s') - V^{\pi}(s), \quad s'=S(s,a).\]</div>
</p>
<dl class="simple">
<dt>Where :</dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(R(s,a)\)</span> is the rewards function</p></li>
<li><p><span class="math notranslate nohighlight">\(V^{\pi}(s)\)</span> is the value function</p></li>
<li><p><span class="math notranslate nohighlight">\(S(s,a)\)</span> is the next state function.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="codpy.KQLearning.KQLearning">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">codpy.KQLearning.</span></span><span class="sig-name descname"><span class="pre">KQLearning</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma=0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_type=&lt;class</span> <span class="pre">'codpy.KQLearning.GamesKernel'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#KQLearning"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.KQLearning" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#codpy.KQLearning.KActorCritic" title="codpy.KQLearning.KActorCritic"><code class="xref py py-class docutils literal notranslate"><span class="pre">KActorCritic</span></code></a></p>
<p>Implements KQLearning algorithm. Uses clustering by default in the <code class="xref py py-func docutils literal notranslate"><span class="pre">train()</span></code> method.</p>
<p>Initializes the KAgent with the given parameters. Every agent has an actor and critic kernel. Some classes might not use both.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>actions_dim</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> The action dimension of the environment.</p></li>
<li><p><strong>state_dim</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> The state dimension of the environment.</p></li>
<li><p><strong>gamma</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> Discount factor.</p></li>
<li><p><strong>kernel_type</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">codpy.kernel.Kernel</span></code> Type of kernel to be used as actor and critic.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="codpy.KQLearning.PolicyGradient">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">codpy.KQLearning.</span></span><span class="sig-name descname"><span class="pre">PolicyGradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#PolicyGradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.PolicyGradient" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#codpy.KQLearning.KActorCritic" title="codpy.KQLearning.KActorCritic"><code class="xref py py-class docutils literal notranslate"><span class="pre">KActorCritic</span></code></a></p>
<p>PolicyGradient Kernel algorithm. It is policy-based and uses a <a class="reference internal" href="#codpy.KQLearning.GamesKernelClassifier" title="codpy.KQLearning.GamesKernelClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">GamesKernelClassifier</span></code></a> as the actor.</p>
<p>Initializes the KAgent with the given parameters. Every agent has an actor and critic kernel. Some classes might not use both.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>actions_dim</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> The action dimension of the environment.</p></li>
<li><p><strong>state_dim</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> The state dimension of the environment.</p></li>
<li><p><strong>gamma</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> Discount factor.</p></li>
<li><p><strong>kernel_type</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">codpy.kernel.Kernel</span></code> Type of kernel to be used as actor and critic.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="codpy.KQLearning.PolicyGradient.get_advantages">
<span class="sig-name descname"><span class="pre">get_advantages</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">games</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#PolicyGradient.get_advantages"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.PolicyGradient.get_advantages" title="Link to this definition"></a></dt>
<dd><p>Compute
<div class="math notranslate nohighlight">
\[A^{\pi}(s) = \nabla_{y} Q^\pi_k(\cdot) = K(\cdot, Z) \nabla_{y} \theta^\pi.\]</div>
</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>games</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code> SARSD in reverse order.</p></li>
<li><p><strong>policy</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">np.ndarray</span></code> The policy to be used for weigthing the next state-actions.</p></li>
<li><p><strong>kwargs</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code> The  advantages of the policy along with a kernel estimator for new advantages on state-action pairs.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="codpy.KQLearning.KController">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">codpy.KQLearning.</span></span><span class="sig-name descname"><span class="pre">KController</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">actions_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">controller</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#KController"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.KController" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#codpy.KQLearning.KAgent" title="codpy.KQLearning.KAgent"><code class="xref py py-class docutils literal notranslate"><span class="pre">KAgent</span></code></a></p>
<p>Implements the KController algorithm. The specificities of this algorithm is that it uses a heuristic controller to be tuned.</p>
<p>Initializes the KAgent with the given parameters. Every agent has an actor and critic kernel. Some classes might not use both.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>actions_dim</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> The action dimension of the environment.</p></li>
<li><p><strong>state_dim</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> The state dimension of the environment.</p></li>
<li><p><strong>gamma</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> Discount factor.</p></li>
<li><p><strong>kernel_type</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">codpy.kernel.Kernel</span></code> Type of kernel to be used as actor and critic.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="codpy.KQLearning.KController.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">z</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#KController.__call__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.KController.__call__" title="Link to this definition"></a></dt>
<dd><p>The internal tuned heuristic controller directly outputs the action.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>z</strong> – :class:<a href="#id1"><span class="problematic" id="id2">`</span></a>np.ndarray the state</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="codpy.KQLearning.KController.get_function">
<span class="sig-name descname"><span class="pre">get_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#KController.get_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.KController.get_function" title="Link to this definition"></a></dt>
<dd><p>Defines the function to be optimized <span class="math notranslate nohighlight">\({L}(R_{k,\lambda_e},\theta)\)</span>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="codpy.KQLearning.KController.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">game</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#KController.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.KController.train" title="Link to this definition"></a></dt>
<dd><p>Solves for <div class="math notranslate nohighlight">
\[\theta_{n+1} = \arg \max_{\theta \in \Theta_n} \mathcal{L}(R_{k,\lambda_e},\theta), \quad \Theta_{n} = \bar{\theta_e} \cup \Theta_{N,n}\]</div>
</p>
<p>Where <span class="math notranslate nohighlight">\(\Theta_{N,n}\)</span> is a screening around the last <span class="math notranslate nohighlight">\(\theta_n\)</span> and is defined as follow:
<div class="math notranslate nohighlight">
\[\Theta_{N,n} = (\theta_n+\alpha^n \Theta_N) \cap \Theta\]</div>
 with <span class="math notranslate nohighlight">\(\alpha^n\)</span> is a contracting factor and <span class="math notranslate nohighlight">\({L}(R_{k,\lambda_e},\theta)\)</span> is an optimization function which can be defined and tuned based on your needs at <a class="reference internal" href="#codpy.KQLearning.KController.get_function" title="codpy.KQLearning.KController.get_function"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_function()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>game</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code> SARSD in reverse order.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="codpy.KQLearning.KQLearningHJB">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">codpy.KQLearning.</span></span><span class="sig-name descname"><span class="pre">KQLearningHJB</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma=0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_type=&lt;class</span> <span class="pre">'codpy.KQLearning.GamesKernel'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#KQLearningHJB"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.KQLearningHJB" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#codpy.KQLearning.KQLearning" title="codpy.KQLearning.KQLearning"><code class="xref py py-class docutils literal notranslate"><span class="pre">KQLearning</span></code></a></p>
<p>Implements the Hamilton-Jacobi-Bellman Q-learning algorithm.</p>
<p>Initializes the KAgent with the given parameters. Every agent has an actor and critic kernel. Some classes might not use both.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>actions_dim</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> The action dimension of the environment.</p></li>
<li><p><strong>state_dim</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code> The state dimension of the environment.</p></li>
<li><p><strong>gamma</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code> Discount factor.</p></li>
<li><p><strong>kernel_type</strong> – <code class="xref py py-class docutils literal notranslate"><span class="pre">codpy.kernel.Kernel</span></code> Type of kernel to be used as actor and critic.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="codpy.KQLearning.KQLearningHJB.optimal_states_values_function">
<span class="sig-name descname"><span class="pre">optimal_states_values_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">games</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_output</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maxiter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reorder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/codpy/KQLearning.html#KQLearningHJB.optimal_states_values_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#codpy.KQLearning.KQLearningHJB.optimal_states_values_function" title="Link to this definition"></a></dt>
<dd><p>Solve the Bellman equation <div class="math notranslate nohighlight">
\[Q^{\pi}(s_t,a_t) = R(s_t,a_t) + \gamma \int \left[ \sum_{a \in \mathcal{A}} \pi^a(s_t) Q^{\pi}(s',a)\right] d \mathbb{P}_S(s',s_t,a_t).\]</div>

Numerically, we effectively solve for the set of parameters <span class="math notranslate nohighlight">\(\theta\)</span> of the kernel <span class="math notranslate nohighlight">\(K\)</span> such that:
<div class="math notranslate nohighlight">
\[\theta = \Big( K(Z, Z) - \gamma \sum_{a} \pi^a(S)\Gamma(P^a) K(P, Z)\Big)^{-1} R, \quad P = \{ S+F_k(S,a), a \}\]</div>
</p>
<dl class="simple">
<dt>Where:</dt><dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(K(Z,Z)\)</span> is the kernel matrix of the states and actions.</p></li>
<li><p><span class="math notranslate nohighlight">\(P\)</span> is the set of the predicted next state actions possibilities.</p></li>
<li><p><span class="math notranslate nohighlight">\(\Gamma(P^a)\)</span> is the transition probability matrix.</p></li>
<li><p><span class="math notranslate nohighlight">\(K(P,Z)\)</span> is the kernel matrix of the predicted next state actions and the states and actions.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="auto_ch7/ch7_AAD.html" class="btn btn-neutral float-left" title="7.06 Automatic Differentiation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="auto_ch8/index.html" class="btn btn-neutral float-right" title="Chapter 8: Reinforcement learning." accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Philippe G. LeFloch , Jean-Marc Mercier, and Shohruh Miryusupov.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
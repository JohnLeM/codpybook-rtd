
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_ch2\ch2_2.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_ch2_ch2_2.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_ch2_ch2_2.py:


===============================================
2.2 Reproducing kernels and transformation maps
===============================================

In this experiment,

.. GENERATED FROM PYTHON SOURCE LINES 8-83

.. code-block:: Python


    # Importing necessary modules
    import os
    import sys

    curr_f = os.path.join(os.getcwd(), "codpy-book", "utils")
    sys.path.insert(0, curr_f)


    import matplotlib.pyplot as plt
    import numpy as np

    # import CodPy's core module and Kernel class
    from codpy import core
    from codpy.kernel import Kernel

    # from codpy.plotting import plot1D
    # Lets import multi_plot function from codpy utils
    from codpy.plot_utils import multi_plot, plot1D


    def kernel_fun(x=None, kernel_name=None, D=1):
        if x is None:
            x = np.linspace(-3, 3, num=100)
        y = np.zeros([1, D])
        kernel = Kernel(
            set_kernel=core.kernel_setter(kernel_name, None),
            x=x,
            order=1,
        )
        out = kernel.knm(x, y)
        return out


    def kernel_funs_plot():
        kernel_list = [
            "gaussian",
            "tensornorm",
            "absnorm",
            "matern",
            "multiquadricnorm",
            # "multiquadrictensor",
            "sincardtensor",
            # "sincardsquaretensor",
            # "dotproduct",
            "gaussianper",
            "maternnorm",
            "scalarproduct",
        ]

        # Prepare the results for plotting each kernel
        results = [
            (np.linspace(-3, 3, num=100), kernel_fun(kernel_name=kernel_name).flatten())
            for kernel_name in kernel_list
        ]

        # Legends for each kernel in the plot
        legends = kernel_list

        # Plot all kernels using multi_plot in a 4x4 grid
        multi_plot(
            results,
            plot1D,
            f_names=legends,
            mp_nrows=3,
            mp_ncols=3,
            mp_figsize=(16, 12),
        )


    # Run the experiment with CodPy and SciPy models
    # core.KerInterface.set_verbose()
    kernel_funs_plot()
    plt.show()




.. image-sg:: /auto_ch2/images/sphx_glr_ch2_2_001.png
   :alt: gaussian, tensornorm, absnorm, matern, multiquadricnorm, sincardtensor, gaussianper, maternnorm, scalarproduct
   :srcset: /auto_ch2/images/sphx_glr_ch2_2_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 84-88

**Kernel Gram matrix**
**Positive definite kernels and kernel matrices**. A *kernel*, denoted by $k: \mathbb{R}^D \times \mathbb{R}^D \to \mathbb{R}$, is a symmetric real-valued function, that is, satisfying $k(x, y)=k(y, x)$. Given two collections of points in $\mathbb{R}^D$, namely $X = (x^1, \cdots, x^{N_x})$ and $Y = (y^1, \cdots, y^{N_y})$, we define the associated *kernel matrix* $K(X,Y) = \big(k(x^n,y^m) \big) \in \mathbb{R}^{N_x, N_y}$ by
$$K(X, Y) =\left( \begin{array}{ccc} k(x^1,y^1) & \cdots & k(x^1,y^{N_y}) \\ \ddots & \ddots & \ddots \\ k(x^{N_x},y^1) & \cdots & k(x^{N_x},y^{N_y}) \end{array}\right).$$


.. GENERATED FROM PYTHON SOURCE LINES 88-100

.. code-block:: Python

    import pandas as pd

    x = np.random.randn(10, 1)
    kernel = Kernel(
        set_kernel=core.kernel_setter("gaussian", None),
        x=x,
        order=1,
    )

    # Kernel Gram matrix
    print(pd.DataFrame(kernel.knm(x, x)))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

              0         1             2             3  ...             6         7         8             9
    0  1.000000  0.693498  3.843789e-01  2.585185e-04  ...  6.599699e-04  0.675676  0.748489  8.468201e-02
    1  0.693498  1.000000  8.165424e-02  5.805453e-03  ...  1.731917e-05  0.999553  0.270643  8.773385e-03
    2  0.384379  0.081654  1.000000e+00  3.599179e-07  ...  5.042954e-02  0.076333  0.824292  7.031590e-01
    3  0.000259  0.005805  3.599179e-07  1.000000e+00  ...  2.994209e-14  0.006387  0.000009  2.616699e-09
    4  0.220172  0.034464  9.382984e-01  4.832816e-08  ...  1.132086e-01  0.031876  0.619535  8.901780e-01
    5  0.896226  0.927682  1.803222e-01  1.553221e-03  ...  9.860632e-05  0.916584  0.469739  2.682027e-02
    6  0.000660  0.000017  5.042954e-02  2.994209e-14  ...  1.000000e+00  0.000015  0.009096  2.758196e-01
    7  0.675676  0.999553  7.633282e-02  6.387366e-03  ...  1.504919e-05  1.000000  0.257753  7.998329e-03
    8  0.748489  0.270643  8.242920e-01  8.770158e-06  ...  9.096183e-03  0.257753  1.000000  3.439937e-01
    9  0.084682  0.008773  7.031590e-01  2.616699e-09  ...  2.758196e-01  0.007998  0.343994  1.000000e+00

    [10 rows x 10 columns]




.. GENERATED FROM PYTHON SOURCE LINES 101-106

**MMD Matrix**

MMD matrices provide a very useful tool in order to evaluate the accuracy of a computation. To any positive kernel $k : \mathbb{R}^D, \mathbb{R}^D \mapsto \mathbb{R}$, we associate the *discrepancy function* $d_k(x,y)$ defined (for $x,y\in\mathbb{R}^D$) by
$$d_k(x,y) = k(x,x) + k(y,y) - 2k(x,y)$$.
For positive kernels, $d_k(\cdot,\cdot)$ is continuous, non-negative, and satisfies the condition $d_k(x,x) = 0$ (for all relevant $x$)

.. GENERATED FROM PYTHON SOURCE LINES 106-111

.. code-block:: Python



    print(pd.DataFrame(kernel.kernel_distance(x)))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

              0         1         2         3         4         5         6         7         8         9
    0  0.000000  0.613003  1.231242  1.999483  1.559655  0.207549  1.998680  0.648647  0.503023  1.830636
    1  0.613003  0.000000  1.836692  1.988389  1.931071  0.144635  1.999965  0.000894  1.458715  1.982453
    2  1.231242  1.836692  0.000000  1.999999  0.123403  1.639356  1.899141  1.847334  0.351416  0.593682
    3  1.999483  1.988389  1.999999  0.000000  2.000000  1.996894  2.000000  1.987225  1.999982  2.000000
    4  1.559655  1.931071  0.123403  2.000000  0.000000  1.825206  1.773583  1.936248  0.760929  0.219644
    5  0.207549  0.144635  1.639356  1.996894  1.825206  0.000000  1.999803  0.166831  1.060523  1.946359
    6  1.998680  1.999965  1.899141  2.000000  1.773583  1.999803  0.000000  1.999970  1.981808  1.448361
    7  0.648647  0.000894  1.847334  1.987225  1.936248  0.166831  1.999970  0.000000  1.484495  1.984003
    8  0.503023  1.458715  0.351416  1.999982  0.760929  1.060523  1.981808  1.484495  0.000000  1.312013
    9  1.830636  1.982453  0.593682  2.000000  0.219644  1.946359  1.448361  1.984003  1.312013  0.000000




.. GENERATED FROM PYTHON SOURCE LINES 112-113

Kernels 2D visualisation

.. GENERATED FROM PYTHON SOURCE LINES 113-184

.. code-block:: Python



    # Lets define helper function to plot 3D projection of the function
    def plot_trisurf(xfx, ax, legend="", elev=90, azim=-100, **kwargs):
        from matplotlib import cm

        """
        Helper function to plot a 3D surface using a trisurf plot.

        Parameters:
        - xfx: A tuple containing the x-coordinates (2D points) and their 
          corresponding function values.
        - ax: The matplotlib axis object for plotting.
        - legend: The legend/title for the plot.
        - elev, azim: Elevation and azimuth angles for the 3D view.
        - kwargs: Additional keyword arguments for further customization.

        """

        xp, fxp = xfx[0], xfx[1]
        x, fx = xp, fxp

        X, Y = x[:, 0], x[:, 1]
        Z = fx.flatten()
        ax.plot_trisurf(X, Y, Z, antialiased=False, cmap=cm.jet)
        ax.view_init(azim=azim, elev=elev)
        ax.title.set_text(legend)


    def generate2Ddata(sizes_x):
        data_x = np.random.uniform(-1, 1, (sizes_x, 2))

        kernel_list = [
            "gaussian",
            "tensornorm",
            "absnorm",
            "matern",
            "multiquadricnorm",
            # "multiquadrictensor",
            "sincardtensor",
            # "sincardsquaretensor",
            # "dotproduct",
            "gaussianper",
            "maternnorm",
            "scalarproduct",
        ]

        # Prepare the results for plotting each kernel
        results = [
            (data_x, kernel_fun(data_x, kernel_name, D=2).flatten())
            for kernel_name in kernel_list
        ]

        # Legends for each kernel in the plot
        legends = kernel_list

        # Plot all kernels using multi_plot in a 4x4 grid
        multi_plot(
            results,
            plot_trisurf,
            f_names=legends,
            mp_nrows=3,
            mp_ncols=3,
            mp_figsize=(12, 16),
            elev=30,
            projection="3d",
        )


    generate2Ddata(400)
    plt.show()
    pass


.. image-sg:: /auto_ch2/images/sphx_glr_ch2_2_002.png
   :alt: gaussian, tensornorm, absnorm, matern, multiquadricnorm, sincardtensor, gaussianper, maternnorm, scalarproduct
   :srcset: /auto_ch2/images/sphx_glr_ch2_2_002.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 6.349 seconds)


.. _sphx_glr_download_auto_ch2_ch2_2.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: ch2_2.ipynb <ch2_2.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: ch2_2.py <ch2_2.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: ch2_2.zip <ch2_2.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 6.4 Unsupervised learning: Clustering - Fraud detection \n\nWe show how to reproduce the results of the chapter 6.3.3 - Credit card fraud dectection. \nWe will compare the codpy MMD minimization-based algorithm with scikit learn k-means in an unsupervised setting. \nThe goal is to show the different scores as we increase the number of centroids Ny used for clustering. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Necessary Imports\n ------------------------\n########################################################################\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import sys\nimport os \nimport time\nimport seaborn as sns\n\nimport pandas as pd\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import train_test_split\nimport kagglehub\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom codpy.clustering import GreedySearch, SharpDiscrepancy\nfrom codpy.kernel import *\nfrom codpy.data_processing import hot_encoder\nfrom ch6_Clustering import *\nfrom sklearn.cluster import KMeans\n\ntry:\n    current_dir = os.path.dirname(__file__)\n    data_dir = os.path.join(current_dir, \"data\")\nexcept NameError:\n    current_dir = os.getcwd()\n    data_dir = os.path.join(current_dir, \"data\")\n\ncurr_f = os.path.join(os.getcwd(), \"codpybook\", \"utils\")\nsys.path.insert(0, curr_f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CreditCardFraud Data Preparation\n ------------------------\nWe get the data from Kagglehub. We scale the values using RobustScaler, which is robust to outliers.\nThis is usefull for the CreditCardFraud dataset, which contains a very small percentage of fraudulent transactions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_dataset():\n    path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n\n    print(\"Path to dataset files:\", path)\n\n    data = pd.read_csv(os.path.join(path, \"creditcard.csv\"))\n    return data \n\ndef prep_data(x,n):\n    rob_scaler = RobustScaler()\n    x[\"Time\"] = rob_scaler.fit_transform(x['Time'].values.reshape(-1,1))\n    x[\"Amount\"] = rob_scaler.fit_transform(x['Amount'].values.reshape(-1,1))\n\n    x = x[:n]\n    frauds = x[x[\"Class\"]==1]\n    no_frauds = x[x[\"Class\"]==0]\n    train_size = 0.8\n\n    x_train_fraud, z_test_fraud= train_test_split(frauds, train_size=train_size, random_state=42)\n    x, z = train_test_split(no_frauds, train_size=train_size, random_state=42)\n    x = pd.concat([x,x_train_fraud])\n    z = pd.concat([z,z_test_fraud])\n\n    fx = x['Class']\n    x = x.drop(['Class'],axis=1)\n    fz = z['Class']\n    z = z.drop(['Class'],axis=1)\n\n    fx, fz = (\n        hot_encoder(pd.DataFrame(data=fx.values), cat_cols_include=[0], sort_columns=True),\n        hot_encoder(pd.DataFrame(data=fz.values), cat_cols_include=[0], sort_columns=True),\n    )\n    x, fx, z, fz = (x.to_numpy(), fx.to_numpy(), z.to_numpy(), fz.to_numpy())\n\n    return x,fx,z,fz\n\ndef fraud_generator(n):\n    return prep_data(get_dataset(),n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running the Experiment\n ------------------------\nThis section runs the experiment to compare K-means and CodPy clustering.\nWe use the models defined in 6.3 Unsupervised learning: Clustering - MNIST\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def one_experiment(X, fx, Ny, get_predictor, z, fz):\n    def get_score(X, cluster_centers, predictor):\n        inertia = compute_inertia(X, cluster_centers)\n        mmd = compute_mmd(X, cluster_centers)\n\n        f_z = predictor(z)\n        f_z = f_z.argmax(1)\n        ground_truth = fz.argmax(axis=-1)\n        out = confusion_matrix(ground_truth, f_z)\n\n        return inertia, mmd, out\n\n    elapsed_time = time.time()\n    cluster_centers, predictor = get_predictor(X, fx, Ny)\n    elapsed_time = time.time() - elapsed_time\n    inertia, mmd, conf_matrix = get_score(X, cluster_centers, predictor)\n    return inertia, mmd, elapsed_time, conf_matrix\n\ndef run_experiment(data_generator, Nx, Ny_values, get_predictors, labels, file_name=None):\n    results = []\n    conf_matrices = {}\n    for Ny in Ny_values:\n        N_MNIST_pics = Nx\n        x, fx, z, fz = data_generator(N_MNIST_pics)\n        for get_predictor, label in zip(get_predictors, labels):\n            inertia, mmd, elapsed_time, conf_matrix = one_experiment(x, fx, Ny, get_predictor, z, fz)\n            print(\n                \"Method:\",label,\n                \"N_partition:\",Ny,\n                \" inertia:\",inertia,\n                \" mmd:\",mmd,\n                \" time:\",elapsed_time,\n            )\n            results.append(\n                {\n                    \"Method\": label,\n                    \"Nx\": Nx,\n                    \"Ny\": Ny,\n                    \"Execution Time (s)\": elapsed_time,\n                    \"inertia\": inertia,\n                    \"mmd\": mmd,\n                }\n            )\n            conf_matrices[label] = conf_matrix\n    out = pd.DataFrame(results)\n    print(out)\n    if file_name is not None:\n        out.to_csv(file_name, index=False)\n    conf_matrices = [{\"data\": conf_mat} for label, conf_mat in conf_matrices.items()]\n    return results, conf_matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting\n ------------------------\nThis section formats data plots the different experiments on a figure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_experiment(inputs):\n    \"\"\"\n        This is mainly boilerplate formatting the data for plotting.\n    \"\"\"\n    results = [{\"data\": {}} for _ in range(3)]\n    for res in inputs:\n        ny = res[\"Ny\"]\n        method = res[\"Method\"]\n        t = res[\"Execution Time (s)\"]\n        inertia = res[\"inertia\"]\n        mmd = res[\"mmd\"]\n        results[0][\"data\"].setdefault(ny, {})[method] = mmd\n        results[1][\"data\"].setdefault(ny, {})[method] = inertia\n        results[2][\"data\"].setdefault(ny, {})[method] = t\n\n \n    def plot_one(inputs):\n        results = inputs[\"data\"]\n        ax = inputs[\"ax\"]\n        legend = inputs[\"legend\"]\n        for model_name in next(iter(results.values())).keys():\n            x_vals = sorted(results.keys())\n            y_vals = [results[x][model_name] for x in x_vals]\n            ax.plot(x_vals, y_vals, marker='o', label=model_name)\n        ax.set_xlabel('Ny')\n        ax.set_ylabel(legend)\n        ax.legend()\n        ax.grid(True)\n\n        return ax\n\n    multi_plot(\n        results,\n        plot_one,\n        mp_nrows=1,\n        mp_ncols=4,\n        mp_figsize=(14, 10),\n        legends=[\"discrepancy_errors\", \"inertia\", \"execution_time\"],\n    )\n\ndef plot_conf_matrix(inputs):\n    conf_matrix = inputs[\"data\"]\n    ax = inputs[\"ax\"]\n    legend = inputs[\"legend\"]\n    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=ax)\n    ax.set_xlabel('Predicted labels')\n    ax.set_ylabel('True labels')\n    ax.set_title(legend)\n    return ax \n\nif __name__ == \"__main__\":\n    get_predictors = [\n        lambda X, fx, N: codpy_clustering(X, fx, N),\n        lambda X, fx, N: kmeans_clustering(X, fx, N),\n    ]\n    labels = [\"greedy\", \"kmeans\"]\n    # Run the experiment\n    Nxs, Nys = 4096*4, [10, 20]\n\n    results, conf_matrices = run_experiment(fraud_generator, Nxs, Nys, get_predictors, labels)\n    plot_experiment(results)\n    plt.show()\n    multi_plot(conf_matrices, plot_conf_matrix, mp_nrows=1, mp_ncols=2, mp_figsize=(14, 10), legends=[\"MMD Codpy\", \"k-means\"])\n    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
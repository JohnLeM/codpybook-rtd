{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 5.6.a Application of OT in Disitribution Sampling : 1D\n\nThis section introduces the concept of partition of unity in the context of\nkernel methods and how CodPy implements it via projection operators.\n\n## Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\nfrom codpy import core\nfrom codpy.kernel import Kernel,Sampler\n\n\ndef normal_wrapper(center, size, radius=1.0, **kwargs):\n    return np.random.normal(loc=center, scale=radius, size=size)\n\n\ndef student_wrapper(center, size, **kwargs):\n    df = kwargs.get(\"df\", 3.0)\n    out = np.random.standard_t(df, size=size)\n    out += center\n    return out\n\n\ndef generate_multimodal_data(\n    N=500,\n    D=1,\n    num_clusters=2,\n    centers=None,\n    radii=None,\n    weights=None,\n    random_variable=None,\n    **kwargs,\n):\n    \"\"\"\n    Generate synthetic multimodal data from a mixture of clusters.\n\n    Parameters:\n        N (int): Total number of samples.\n        D (int): Dimensionality of the data.\n        num_clusters (int): Number of clusters.\n        centers (np.ndarray): Optional. Shape (num_clusters, D).\n        radii (np.ndarray): Optional. Std dev per cluster.\n        weights (np.ndarray): Optional. Cluster weights (should sum to 1).\n        random_variable (callable): Custom sampling function. Default is np.random.normal.\n\n    Returns:\n        x (pd.DataFrame): Data samples.\n        labels (pd.Series): Cluster labels for each sample.\n    \"\"\"\n    if centers is None:\n        centers = np.random.normal(loc=0.0, scale=3.0, size=(num_clusters, D))\n        centers -= centers.mean(axis=0)\n\n    if radii is None:\n        radii = np.abs(np.random.normal(loc=1.0, scale=0.5, size=num_clusters))\n\n    if weights is None:\n        weights = np.ones(num_clusters) / num_clusters\n\n    if random_variable is None:\n        random_variable = normal_wrapper\n\n    x_list, label_list = [], []\n\n    for i in range(num_clusters):\n        num_samples = int(N * weights[i])\n        samples = random_variable(\n            center=centers[i], size=(num_samples, D), radius=radii[i], **kwargs\n        )\n        x_list.append(samples)\n        label_list.extend([i] * num_samples)\n\n    x = pd.DataFrame(np.vstack(x_list), columns=[f\"dim_{d}\" for d in range(D)])\n    labels = pd.Series(label_list, name=\"cluster\")\n    return x, labels\n\n\ndef hist_plot(ref, sampled, ax=None, title=\"\"):\n    if ax is None:\n        ax = plt.gca()\n    ax.hist(ref, bins=50, alpha=0.5, label=\"Reference\")\n    ax.hist(sampled, bins=50, alpha=0.5, label=\"Sampled\")\n    ax.set_title(title)\n    ax.legend()\n\n\ndef df_summary(df):\n    return pd.DataFrame(\n        {\n            \"Mean\": df.mean(),\n            \"Variance\": df.var(),\n            \"Skewness\": df.skew(),\n            \"Kurtosis\": df.kurtosis(),\n        }\n    )\n\n\nfrom scipy.stats import ks_2samp\n\n\ndef ks_testD(x, y, alpha=0.05):\n    \"\"\"\n    Performs Kolmogorov-Smirnov test for each dimension.\n\n    Parameters:\n        x (np.ndarray or pd.DataFrame): First sample.\n        y (np.ndarray or pd.DataFrame): Second sample.\n        alpha (float): Significance level (default 0.05).\n\n    Returns:\n        pd.Series: p-values from the KS test.\n        pd.Series: Constant threshold values (same for all dimensions).\n    \"\"\"\n    x = x.values if isinstance(x, pd.DataFrame) else x\n    y = y.values if isinstance(y, pd.DataFrame) else y\n\n    D = x.shape[1]\n    p_values = []\n    thresholds = []\n\n    for i in range(D):\n        stat = ks_2samp(x[:, i], y[:, i])\n        p_values.append(stat.pvalue)\n        thresholds.append(alpha)  # Optional: could vary if computed per dim\n\n    return pd.Series(p_values, name=\"p-value\"), pd.Series(thresholds, name=\"threshold\")\n\n\ndef stats_df(dfx_list, dfy_list, f_names=None, fmt=\"{:.2g}\"):\n    \"\"\"\n    Computes and formats summary statistics between reference and sampled data.\n\n    Parameters:\n        dfx_list (list): List of reference datasets (np.ndarray or pd.DataFrame).\n        dfy_list (list): List of sampled datasets (np.ndarray or pd.DataFrame).\n        f_names (list): Optional. Row labels. Should match total number of columns across all datasets.\n        fmt (str): Format string for floats.\n\n    Returns:\n        pd.DataFrame: Formatted summary statistics.\n    \"\"\"\n\n    if not isinstance(dfx_list, list):\n        dfx_list = [dfx_list]\n    if not isinstance(dfy_list, list):\n        dfy_list = [dfy_list]\n\n    def format_pair(x_vals, y_vals):\n        return [f\"{fmt.format(x)} ({fmt.format(y)})\" for x, y in zip(x_vals, y_vals)]\n\n    all_stats, full_index = [], []\n    for i, (dfx, dfy) in enumerate(zip(dfx_list, dfy_list)):\n        dfx = pd.DataFrame(dfx)\n        dfy = pd.DataFrame(dfy)\n\n        sx, sy = df_summary(dfx), df_summary(dfy)\n        ks_df, ks_thr = ks_testD(dfx, dfy)\n\n        stats = {\n            \"Mean\": format_pair(sx.Mean, sy.Mean),\n            \"Variance\": format_pair(sx.Variance, sy.Variance),\n            \"Skewness\": format_pair(sx.Skewness, sy.Skewness),\n            \"Kurtosis\": format_pair(sx.Kurtosis, sy.Kurtosis),\n            \"KS test\": format_pair(ks_df, ks_thr),\n        }\n\n        all_stats.append(pd.DataFrame(stats, index=dfx.columns))\n        if f_names and i < len(f_names):\n            full_index.extend([f\"{f_names[i]}:{col}\" for col in dfx.columns])\n        else:\n            full_index.extend(dfx.columns)\n\n    result = pd.concat(all_stats)\n    result.index = full_index\n    return result\n\n\ndef compare_distributions_1d(N=300, Nz=500):\n    \"\"\"\n    Compare Gaussian and Student-t distributions using 1D sampling and histogram plotting.\n    \"\"\"\n    # Generate Gaussian data\n    y_gauss_df, _ = generate_multimodal_data(N=N, D=1)\n    y_gauss = y_gauss_df.values\n    sampler_gauss = Sampler(x=y_gauss)\n    sampled_gauss = sampler_gauss.sample(Nz)\n\n    # Generate Student-t data\n    y_student_df, _ = generate_multimodal_data(\n        N=N, D=1, random_variable=student_wrapper\n    )\n    y_student = y_student_df.values\n    sampler_student = Sampler(y_student)\n    sampled_student = sampler_student.sample(Nz)\n\n    # Plot\n    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n    hist_plot(y_gauss, sampled_gauss, ax=axes[0], title=\"Gaussian Distribution\")\n    hist_plot(y_student, sampled_student, ax=axes[1], title=\"Student-t Distribution\")\n    plt.tight_layout()\n    plt.show()\n\n    return stats_df(\n        [y_gauss, y_student],\n        [sampled_gauss, sampled_student],\n        f_names=[\"Gaussian\", \"Student-t\"],\n    )\n\nstats = compare_distributions_1d()\nstats.to_latex(\n    \"ch5_6_a.tex\",\n    index=True,\n    float_format=\"%.2g\",\n    caption=\"Comparison of Gaussian and Student-t distributions using 1D sampling.\",\n    label=\"tab:ch5_6_a\",\n)\nprint(stats)\npass"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
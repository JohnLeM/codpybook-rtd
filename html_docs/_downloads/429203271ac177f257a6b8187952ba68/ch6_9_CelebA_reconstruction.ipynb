{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 6.4.1 Generating complex distributions\n\nWe reproduce the Figure 6.10 from the book, reconstructing a new image not in the dataset.\nWe train our model on the CelebA dataset, and then, using a test image, we reconstruct it from its latent representation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Necessary Imports\n ------------------------\nEverything is already made in the previous file, so we just import it here.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.special import softmax\n\nfrom ch6_9_CelebA import * \n\nconfig = {\n    'input_shape':[218,178],\n    'rescale_shape':[50,50],\n    'Nx':1000,  # Number of images to use for training\n    'Nz':16, # Numer of images to generate\n    'seed':43,\n    \"main_folder\":os.path.join(data_path,'celebA'),\n}\ndef reconstruction_high_dimension(\n        kwargs = config,\n        selected_features=['Young', 'Blond_Hair','Attractive','Smiling'],\n        drop_features=['Male'],\n        dimensions = [40]\n        ):\n\n    kwargs['Nz'] = 1 \n\n    # Load images\n    celeba = CelebA_data_generator(selected_features=selected_features,drop_features=drop_features)\n    x_target,fx,y = celeba.get_data(**kwargs)\n    # We keep the first one for testing\n    x_target = x_target.values\n\n    test = x_target[0]\n    print(f\"Loaded {kwargs['Nx']} images\")\n\n    # This will enable us to sample from the latent space\n    # We don't pass the first image, as it is used for testing\n    for d in dimensions:\n        sampler = Sampler(x=x_target[1:], latent_dim=d, iter=0)\n        # We need a kernel to encode the testing image into latent space\n        origin_latent = sampler.get_x() # (Nx, d)\n        encoder = Kernel(x=x_target[1:], fx=origin_latent, order=2)\n    \n        # Encode the testing image into latent space\n        test_latent = encoder(z=test.reshape(1,-1))\n        # Reconstruct it in the downascaled space\n        test_reconstruct = sampler(z=test_latent) # (1, kwargs['input_shape'])    \n\n        # Computing distance between original and generated in latent space\n        dist = sampler.dnm(x=test_latent, y=origin_latent) # (1, Nx)\n        \n        # Aligned idxs in latent space\n        indices = np.argmin(dist, axis=1) # (1,)\n        \n        # Getting back original closest to the reconstructed image in latent space\n        origin = sampler(origin_latent[indices]) # (1, kwargs['input_shape'])\n        \n        result = np.concatenate([test.reshape(1,-1), test_reconstruct, origin], axis=0) # (3, kwargs['input_shape'])\n        result_tile = tiles(result,pic_shape=kwargs['input_shape'],tile_shape=[1,3])\n        pic_name = str(kwargs['Nx'])+\"D_\"+str(d)+\".png\"\n        plt.imsave(os.path.join(proj_path,\"pic_reconstructed_N\"+pic_name),result_tile, vmin=0., vmax = 1.)\n        plt.show()\n        print(\"Saved\",pic_name)\n\nreconstruction_high_dimension(dimensions = [8])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
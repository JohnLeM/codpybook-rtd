{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 5.3.3 Kernel Conditional Density\nIn this experiment, we reproduce the results from the chapter 5.3.3 of the book.\nSpefically, we will benchmark the performance of different conditional density estimators.\nWe will use generated data and compare Nadaraya-Watson with the Projection-based estimator from CodPy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Required imports\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import norm\n\nimport codpy.core\nfrom codpy.conditioning import ConditionerKernel, NadarayaWatsonKernel\nfrom codpy.core import kernel_setter\nfrom codpy.utils import cartesian_outer_product, get_matrix\n\ncodpy.core.KerInterface.set_verbose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating the data\nThe data is generated according to the chapter 5.3.3 of the book. - Illustrative example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def mean_function_hard(x):\n    return np.cos(np.pi / 2 * x)\n    # return np.sin(np.pi * x)\n\n\ndef variance_function(x):\n    return 0.1 * np.cos(np.pi * x * 0.5)\n\n\ndef mean_function(x):\n    return 0.1 * np.cos(np.pi * x * 0.5)\n\n\ndef variance_function_hard(X):\n    return 0.3 - 0.1 * mean_function(X)\n\n\ndef generate_conditional_hetero_skedastic_density_data(\n    N_train=1000, seed=None, mean_f=None, variance_f=None\n):\n    \"\"\"\n    Generate synthetic data with nonlinear and heteroscedastic structure.\n\n    Parameters:\n    - N_train: Number of training samples (X, Y)\n    - seed: Random seed for reproducibility\n    - mean_f: Callable for mean function, e.g., mean_function(x)\n    - variance_f: Callable for variance function, e.g., variance_function(x)\n\n    Returns:\n    - x: Training input samples (1D array)\n    - y: Training output samples (1D array)\n    - z: Test input sample (scalar)\n    - y_pdf: Grid of y values for PDF estimation\n    - (fz_mean, fz_std): True conditional mean and std at z\n    - density: True conditional density at z over y_pdf\n    \"\"\"\n    if seed is not None:\n        np.random.seed(seed)\n\n    if mean_f is None:\n        mean_f = mean_function\n    if variance_f is None:\n        variance_f = variance_function\n\n    x = np.random.uniform(-1.0, 1.0, N_train)\n    mean_y = mean_f(x)\n    std_y = variance_f(x)\n\n    y = np.random.normal(loc=mean_y, scale=std_y)\n\n    z = 0.0\n    fz_mean = mean_f(z)\n    fz_std = variance_f(z)\n\n    y_pdf = np.linspace(2.0 * y.min(), 2.0 * y.max(), N_train)\n    density = norm.pdf(y_pdf, loc=fz_mean, scale=fz_std)\n    density /= density.sum(axis=0)\n\n    return x, y, z, y_pdf, (fz_mean, fz_std), density\n\n\nx, y, z, y_pdf, (fz_mean, fz_std), density = (\n    generate_conditional_hetero_skedastic_density_data(\n        N_train=1000,\n        seed=None,\n        mean_f=mean_function,\n        variance_f=variance_function,\n    )\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the data\nWe plot the data with the test points z and true conditional density p(y | z).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_data_with_test_point(x, y, z, y_pdf):\n    plt.figure(figsize=(10, 6))\n    plt.scatter(x, y, alpha=0.4, label=\"Training Data (X, Y)\", s=10)\n\n    # Mark test point z\n    out = cartesian_outer_product(get_matrix(z), get_matrix(y_pdf)).squeeze()\n    plt.scatter(out[:, 0], out[:, 1], color=\"red\", label=\"Test set\", s=0.3, alpha=0.5)\n\n    plt.title(\"Training Data with Test Point\")\n    plt.xlabel(\"x\")\n    plt.ylabel(\"y\")\n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()\n\n\nplot_data_with_test_point(x, y, z, y_pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estimators\nWe now use Nadaraya-Watson, CodPy's Conditioner, and KDE to estimate the conditional density.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x, y, y_pdf, z = (\n    x.reshape(-1, 1),\n    y.reshape(-1, 1),\n    y_pdf.reshape(-1, 1),\n    np.array(z).reshape(-1, 1),\n)\n\n\n# For Kde, we use NadarayaWatsonKernel with the map set to bandwith.\nnw = NadarayaWatsonKernel(\n    x=x,\n    y=y,\n    set_kernel=kernel_setter(kernel_string=\"gaussian\",kernel_args= {\"bandwidth\", 12}),\n)\nkde_result = nw.joint_density(y_pdf, z)\nkde_result = kde_result.reshape(-1, 1)\nkde_result /= kde_result.sum(axis=0)\n\n# Without any specific kernel and maps, the default NadarayaWatson is used.\n\nX_eval = np.linspace(-1, 1, 1000)\nkde_bandwidth = 13\n# kde_model = NadarayaWatsonKernel(\n#     x=x, y=y, set_kernel=kernel_setter(\"gaussian\", \"bandwidth\", bandwidth=kde_bandwidth)\n# )\n# mean_codpy = kde_model.expectation(\n#     X_eval,\n#     reg=0.1,\n# )\ncodpy_model = ConditionerKernel(x=x, y=y)\nmean_codpy = codpy_model.expectation(X_eval, reg=1.5)\n\n\n# y_demeaned = y.reshape(-1, 1) - mean_codpy.reshape(-1, 1)\n\n# nw = NadarayaWatsonKernel(x=x, y=y_demeaned)\nnw = NadarayaWatsonKernel(x=x, y=y)\nnw_result = nw.joint_density(y_pdf, z)\nnw_result = nw_result.reshape(-1, 1)\nnw_result /= nw_result.sum(axis=0)\n\n\ncodpy = ConditionerKernel(x=x, y=y)\ncodpy_result = codpy.get_transition(y=y_pdf, x=z)\ncodpy_result /= codpy_result.sum(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_conditional_estimates(y_pdf, true_density, nw, kde, codpy, z):\n    plt.figure(figsize=(10, 6))\n\n    plt.plot(y_pdf, true_density, \"k-\", lw=2, label=f\"True $p(y|z={z.item():.2f})$\")\n    plt.plot(y_pdf, nw, \"r--\", lw=2, label=\"Nadaraya-Watson\")\n    plt.plot(y_pdf, kde, \"b-.\", lw=2, label=\"Nadaraya-Watson (with bandwidth)\")\n    plt.plot(y_pdf, codpy, \"g:\", lw=2, label=\"CodPy ConditionerKernel\")\n\n    plt.title(f\"Estimated Conditional Densities at z = {z.item():.2f}\")\n    plt.xlabel(\"y\")\n    plt.ylabel(\"Density\")\n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n\n\nfig, axes = plt.subplots(1, 1, figsize=(14, 5))\nX_eval = np.linspace(-1, 1, 1000)\nkde_bandwidth = 13\nz = np.array(0.0).reshape(-1, 1)\n\n\nx, y, z_scalar, y_pdf, (fz_mean, fz_std), true_density = (\n    generate_conditional_hetero_skedastic_density_data(\n        N_train=1000,\n        seed=3,\n        mean_f=mean_function,\n        variance_f=variance_function,\n    )\n)\ny_pdf = y_pdf.reshape(-1, 1)\nx = x.reshape(-1, 1)\ny = y.reshape(-1, 1)\nz = np.array(z_scalar).reshape(-1, 1)\n\n# KDE with fixed bandwidth\nkde_model = NadarayaWatsonKernel(\n    x=x, y=y, set_kernel=kernel_setter(kernel_string=\"gaussian\",kernel_args= {\"bandwidth\", 12})\n)\nkde_result = kde_model.joint_density(y_pdf, z)\nkde_result /= kde_result.sum()\n\n# Nadaraya-Watson with de-meaned residuals\nnw_model = NadarayaWatsonKernel(x=x, y=y)\nnw_result = nw_model.joint_density(y_pdf, z)\nnw_result /= nw_result.sum()\n\n# CodPy density estimate\ncodpy = ConditionerKernel(x=x, y=y)\ncodpy_result = codpy.get_transition(y=y_pdf, x=z)\ncodpy_result /= codpy_result.sum()\n\nplt.plot(y_pdf, true_density, \"k-\", lw=2, label=\"True\")\nplt.plot(y_pdf, nw_result.reshape(-1, 1), \"r-.\", lw=2, label=\"NW\")\nplt.plot(y_pdf, kde_result.reshape(-1, 1), \"b-.\", lw=2, label=\"NW with wb\")\nplt.plot(y_pdf, codpy_result.reshape(-1, 1), \"g:\", lw=2, label=\"CodPy\")\n\nplt.title(r\"Conditional Density Estimate ($\\mu(x) = \\sin(\\pi x)$)\")\nplt.xlabel(\"y\")\nplt.ylabel(\"Density\")\nplt.grid(True)\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\npass"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
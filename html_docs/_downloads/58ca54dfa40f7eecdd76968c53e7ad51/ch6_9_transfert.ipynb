{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 6.4.5 Conditioning on discrete distributions of celebA dataset\n\nWe reproduce the Figure 6.15 from the book.\nWe train a model on the CelebA dataset, conditionned on the features. \nWe then select 10 images with hats and eyeglasses, and slowly generate new images \nBy varying the strength of those features, resulting in a verion of \"no hats and eyeglasses\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Necessary Imports\n ------------------------\nEverything is already made in the previous file, so we just import it here.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ch6_9_CelebA import * \n\n\nconfig = {\n    'input_shape':[218,178],\n    'rescale_shape':[50,50],\n    'Nx':1000,  # Number of images to use for training\n    'Nz':4, # Numer of images to generate\n    'seed':40,\n    \"main_folder\":os.path.join(data_path,'celebA'),\n}\ndef style_transferts(\n      selected_features=['Young','Attractive'],\n      drop_features=['Male','Heavy_Makeup'],\n      conditionned_features=['Wearing_Hat','Eyeglasses'],\n      other_features=['Blond_Hair','Smiling'],\n      dimension = 2,\n      **kwargs\n    ):\n\n    n_images = config['Nx']\n    Nz = config['Nz']\n    # Collect all images\n    celeba = CelebA_data_generator(selected_features=selected_features,drop_features=drop_features)\n    x_target_all, img_paths_all, features_all = celeba.get_data(conditionned_features=conditionned_features,**kwargs)\n    features_all.drop(columns='path', inplace=True)  # Remove the path column\n    # pics = tiles(x_target_all.loc[['005350.jpg']].values,pic_shape=kwargs['input_shape'],tile_shape=[1,1])  \n    # plt.imshow(pics)  \n\n    # We get those with hats and/or eyeglasses\n    if len(other_features) > 0:\n        features_all = features_all[conditionned_features+other_features]\n    \n    all_conditionned_and = features_all.copy()\n    for f in conditionned_features:\n        all_conditionned_and = all_conditionned_and.loc[all_conditionned_and[f]==+1]    \n    # idx_and = all_conditionned_and.index[:Nz]\n    idx_and = all_conditionned_and.index\n\n    print(f\"selected ids: {idx_and}\")\n    # We get again new images with none of those, whatever remains from the required initial number of images\n    features_and = features_all.loc[idx_and].copy()\n    # all_features = features.values[:,:-1] # Remove the last column which is the image path\n\n    all_features = features_all.reset_index()\n    x_target_all = x_target_all.reset_index()  \n    idx_and = all_features[all_features['image_id'].isin(idx_and)].index\n    x_target_all.drop(columns='image_id', inplace=True)  # Remove the image_id column\n    all_features.drop(columns='image_id', inplace=True)  # Remove the image_id column\n    print(f\"Dataset Ready\")\n\n    # We condition y | x\n    # y are our images\n    # x are our features\n    conditionner = codpy.conditioning.ConditionerKernel(\n        x=all_features,\n        y=x_target_all,\n        latent_dim_y=dimension\n    )\n\n    conditionner.set_maps(iter=0)\n\n    permut_idx_and = map_invertion(np.array(conditionner.sampler_xy.permutation))[idx_and]\n    latent_values_y = conditionner.latent_y\n    latent_values_y_and = latent_values_y[permut_idx_and]\n    latent_values_x = conditionner.latent_x\n    latent_values_x_and = latent_values_x[permut_idx_and]\n\n    #compute latent values of selected pictures\n    latent_images_and = np.concatenate([latent_values_x_and,latent_values_y_and],axis=1) # -1 because we remove the img path\n    #check the reconstruction. comment after checking\n    # pics = tiles(conditionner.get_y()[idx_and],pic_shape=kwargs['input_shape'],tile_shape=[1,len(idx_and)])  \n    # plt.imshow(pics) \n    # plt.show() \n    # reconstructed_images = conditionner.sampler_xy(latent_images_and)[:,all_features.shape[1]:]\n    # pics = tiles(reconstructed_images,pic_shape=kwargs['input_shape'],tile_shape=[1,len(idx_and)])  \n    # plt.imshow(pics)  \n    # plt.show() \n\n\n    print(\"conditionner ready\")\n    results=None\n    \n\n    latent_images_and = latent_images_and[:Nz]\n    cond_feat = latent_images_and.copy()\n\n    # feature_strength_list = [1, 0.5, 0.0, -0.5, -1]\n    feature_strength_list = [1, 0.5, 0.0, -0.5, -1]\n    for feature_strength in feature_strength_list:\n        # Update the and features on the conditionned features and extract values \n        cond_feat[:,:len(conditionned_features)] = latent_images_and[:,:len(conditionned_features)]*feature_strength\n\n        # Sampling new images \n        sampled_images = conditionner.sampler_xy(cond_feat)[:,all_features.shape[1]:]\n        if results is None:\n            results = sampled_images\n        else:\n            results = np.concatenate([results, sampled_images], axis=0)\n        # print(f\"Added {feature_strength} feature results\")\n    pics = tiles(results,pic_shape=config['input_shape'],tile_shape=[len(feature_strength_list),results.shape[0] // len(feature_strength_list)])\n    plt.imshow(pics) \n    plt.show()\n    pic_name = str(n_images)+\"D_\"+str(dimension)+\".png\"\n    plt.imsave(os.path.join(proj_path,\"pic_transfert_N\"+pic_name),pics, vmin=0., vmax = 1.)\n    print(\"Saved\",pic_name)\n    pass\n\nstyle_transferts(\n      selected_features=['Young','Attractive'],\n      drop_features=['Male','Heavy_Makeup'],\n      conditionned_features=['Eyeglasses','Wearing_Hat'],\n      other_features=['Blond_Hair','Smiling'],\n      dimension = 4,\n      **config)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
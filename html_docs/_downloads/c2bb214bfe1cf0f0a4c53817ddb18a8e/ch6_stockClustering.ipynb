{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 6.5 Unsupervised learning: Clustering - Stock Clustering\n\n\nWe show how to reproduce the results of the chapter 6.3.4 - Application to unsupervised machine learning - Portfolio of stock clustering of the book.\nWe will compare different clusters obtained with the codpy MMD minimization-based algorithm and scikit learn k-means.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Necessary Imports\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport sys\nimport urllib.request\nfrom collections import defaultdict\n\nos.environ[\"OPENBLAS_NUM_THREADS\"] = \"32\"\nos.environ[\"OMP_NUM_THREADS\"] = \"4\"\n\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import HTML\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import Normalizer\n\nfrom codpy.clustering import SharpDiscrepancy\n\ntry:\n    current_dir = os.path.dirname(__file__)\n    data_dir = os.path.join(current_dir, \"data\")\nexcept NameError:\n    current_dir = os.getcwd()\n    data_dir = os.path.join(current_dir, \"data\")\n\ncurr_f = os.path.join(os.getcwd(), \"codpybook\", \"utils\")\nsys.path.insert(0, curr_f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stocks Data Preparation\nWe get the data from a csv, using data from Yahoo Finance.\nThe data is normalized using a standard normalizer from sklearn.preprocessing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def df_standard_normalize(x):\n    return pd.DataFrame(data=Normalizer().fit(x).transform(x.values), index=x.index)\n\n\ndef get_dataset():\n    \"\"\"\n    Loads the dataset from local disk or downloads it from GitHub if not present.\n    \"\"\"\n    data_dir = \"data\"\n    os.makedirs(data_dir, exist_ok=True)\n\n    filename = \"company-stock-movements-2010-2015-incl.csv\"\n    file_path = os.path.join(data_dir, filename)\n    url = \"https://raw.githubusercontent.com/mesfind/datasets/master/company-stock-movements-2010-2015-incl.csv\"\n\n    # Download if not exists\n    if not os.path.exists(file_path):\n        print(f\"File not found locally. Downloading from {url}...\")\n        urllib.request.urlretrieve(url, file_path)\n        print(\"Download complete.\")\n\n    # Read and process the data\n    data = pd.read_csv(file_path, index_col=0)\n    data = df_standard_normalize(data)\n    labels, x = data.index.to_numpy(), data.to_numpy()\n    return labels, x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clustering Models\nThis section defines the K-means and CodPy clustering models.\nBecause we only observe the clusters and don't compare with labels, we only instanciate the clustering models.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def sharp_clustering(x, Ny):\n    # SharpDiscrepancy is a clustering algorithm based on MMD minimization.\n    # It finds cluster centers and assigns labels to the data points.\n    kernel = SharpDiscrepancy(x=x, N=Ny)\n    centers = kernel.cluster_centers_\n    labels = kernel.get_labels()\n    return labels, centers, kernel\n\n\ndef kmeans_clustering(x, Ny):\n    kernel = KMeans(n_clusters=Ny, random_state=1).fit(x)\n    predictor = lambda z: kernel.predict(z)\n    centers = kernel.cluster_centers_\n    labels = kernel.labels_\n    return labels, centers, predictor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the Experiment\nThis section runs the experiment to compare K-means and CodPy clustering.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def run_experiment(data_generator, get_predictors, labels, file_name=None):\n    results = {}\n    N = 10\n    companies, x = data_generator()\n    for get_predictor, label in zip(get_predictors, labels):\n        results[label] = []\n        labels, clusters, _ = get_predictor(x, N)\n        res = np.concatenate(\n            [companies[..., np.newaxis], labels[..., np.newaxis]], axis=1\n        )\n        res = sorted(res, key=lambda x: x[1])\n        res = np.array(res)\n        results[label] = res\n\n    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting\nThis section formats data and prints it as a table.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def build_cluster_dict(data):\n    cluster_dict = defaultdict(list)\n    for name, cluster in data:\n        cluster_dict[int(cluster)].append(name)\n    # Sort clusters by cluster id\n    return dict(sorted(cluster_dict.items()))\n\n\ndef build_table_dataframe(\n    kmeans_clusters, mmd_clusters, max_line_length=40, max_lines=5\n):\n    all_cluster_ids = sorted(set(kmeans_clusters) | set(mmd_clusters))\n    data = {\"#\": [], \"k-means\": [], \"MMD minimization\": []}\n\n    for cluster_id in all_cluster_ids:\n        kmeans_wrapped = sorted(kmeans_clusters.get(cluster_id, []))\n        mmd_wrapped = sorted(mmd_clusters.get(cluster_id, []))\n\n        data[\"#\"].append(str(cluster_id + 1))\n        data[\"k-means\"].append(kmeans_wrapped)\n        data[\"MMD minimization\"].append(mmd_wrapped)\n\n    return pd.DataFrame(data)\n\n\nget_predictors = [\n    lambda X, N: sharp_clustering(X, N),\n    lambda X, N: kmeans_clustering(X, N),\n]\nlabels = [\"sharp disc\", \"kmeans\"]\nresults = run_experiment(get_dataset, get_predictors, labels)\n\nkmeans_clusters = build_cluster_dict(results[\"kmeans\"])\nmmd_clusters = build_cluster_dict(results[\"sharp disc\"])\n\nsave_path = os.path.join(data_dir, \"stock_clustering_results.png\")\ndf = build_table_dataframe(kmeans_clusters, mmd_clusters)\nwith open(save_path.replace(\".png\", \".txt\"), \"w\") as f:\n    f.write(df.to_latex())\nhtml = df.style.set_properties(\n    **{\n        \"white-space\": \"pre-wrap\",\n        \"word-wrap\": \"break-word\",\n        \"max-width\": \"400px\",\n        \"font-family\": \"monospace\",\n    }\n).to_html()\n\nHTML(html)\npass"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
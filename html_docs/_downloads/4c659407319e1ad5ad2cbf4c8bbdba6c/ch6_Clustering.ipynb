{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 6.3 Unsupervised learning: Clustering - MNIST\n\nWe show how to reproduce the results of the chapter 6.3.2 - Application to supervised machine learning - Classification problem: handwritten digits of the book.\nWe will compare the codpy MMD minimization-based algorithm with scikit learn k-means in an unsupervised setting.\nThe goal is to show the different scores as we increase the number of centroids Ny used for clustering.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Necessary Imports\n ------------------------\n########################################################################\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport time\n\nos.environ[\"OPENBLAS_NUM_THREADS\"] = \"32\"\nos.environ[\"OMP_NUM_THREADS\"] = \"4\"\n\nimport random\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom codpy.clustering import GreedySearch, SharpDiscrepancy\n\n# We use a custom hot encoder for performances reasons.\nfrom codpy.kernel import *\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import confusion_matrix, pairwise_distances\nfrom torchvision import datasets, transforms\n\ntry:\n    current_dir = os.path.dirname(__file__)\n    data_dir = os.path.join(current_dir, \"data\")\nexcept NameError:\n    current_dir = os.getcwd()\n    data_dir = os.path.join(current_dir, \"data\")\n\ncurr_f = os.path.join(os.getcwd(), \"codpy-book\", \"utils\")\nsys.path.insert(0, curr_f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MNIST Data Preparation\nWe normalize pixel values and reshape data for processing.\nPixel data is used as flat vectors, and labels are one-hot encoded.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_MNIST_data(N=-1, flatten=True, one_hot=True, seed=43):\n    transform = transforms.ToTensor()\n\n    train_data = datasets.MNIST(\n        root=\".\", train=True, download=True, transform=transform\n    )\n    test_data = datasets.MNIST(\n        root=\".\", train=False, download=True, transform=transform\n    )\n\n    x = train_data.data.numpy().astype(np.float32) / 255.0\n    fx = train_data.targets.numpy()\n\n    z = test_data.data.numpy().astype(np.float32) / 255.0\n    fz = test_data.targets.numpy()\n\n    if flatten:\n        x = x.reshape(len(x), -1)\n        z = z.reshape(len(z), -1)\n\n    if one_hot:\n        fx = np.eye(10)[fx]\n        fz = np.eye(10)[fz]\n    if N == -1:\n        N = x.shape[0]\n    indices = random.sample(range(x.shape[0]), min(N, x.shape[0]))\n    x, fx = x[indices], fx[indices]\n\n    return x, fx, z, fz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clustering Models\nThis section defines the K-means and CodPy clustering models.\nWe wrap the clustering methods with kernels assigning labels to clusters based on the target values `fx`.\nThis allow us to compute score metrics for the models.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def codpy_sharp(x, fx, Ny):\n    # Select the codpy model for clustering and select centers\n    greedy_search = SharpDiscrepancy(x=x, N=Ny)\n    centers = greedy_search.cluster_centers_\n    # Set a classifier which will assign labels to clusters based on fx\n    kernel = KernelClassifier(x=x, y=centers, fx=fx)\n    kernel.set_kernel_ptr(greedy_search.k.kernel)\n    return centers, kernel\n\n\ndef codpy_clustering(x, fx, Ny):\n    # Select the codpy model for clustering and select centers\n    greedy_search = GreedySearch(x=x, N=Ny)\n    centers = greedy_search.cluster_centers_\n    # Set a classifier which will assign labels to clusters based on fx\n    kernel = KernelClassifier(x=x, y=centers, fx=fx)\n    kernel.set_kernel_ptr(greedy_search.k.kernel)\n    return centers, kernel\n\n\ndef kmeans_clustering(x, fx, Ny):\n    # Use Kmeans from sklearn to get the clusters\n    if Ny >= x.shape[0]:\n        centers = x\n    else:\n        centers = KMeans(n_clusters=Ny, random_state=1).fit(x).cluster_centers_\n    # Set a classifier which will assign labels to centers based on fx\n    kernel = KernelClassifier(x=x, y=centers, fx=fx)\n    return centers, kernel\n\ndef compute_mmd(x_test, z):\n    kernel = Kernel(x=x_test, order=0)\n    mmd = kernel.discrepancy(z)\n    return mmd\n\n\ndef compute_inertia(x, y):\n    return np.sum((pairwise_distances(x, y) ** 2).min(axis=1))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
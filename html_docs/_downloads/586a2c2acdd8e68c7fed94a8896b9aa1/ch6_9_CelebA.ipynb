{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 6.4.1 Generating complex distributions from celebA dataset\n\nWe reproduce the Figure 6.9 from the book, generating images from the CelebA dataset.\nWe generate new images from different latent dimension spaces, and compare them to the closest images in the dataset.\nWe define \"closest\" using a distance metric in the latent space between images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Necessary Imports\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import math\nimport os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport skimage.io\nimport skimage.transform\nfrom scipy import optimize\n\nfrom codpy import core\nfrom codpy.kernel import Kernel, Sampler\nfrom codpy.permutation import scipy_lsap, lsap, map_invertion\nimport codpy.conditioning\ntry:\n    current_dir = os.path.dirname(__file__)\n    data_path = os.path.join(current_dir, \"data\")\nexcept NameError:\n    current_dir = os.getcwd()\n    data_path = os.path.join(current_dir, \"data\")\n\nproj_path = data_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Generator\nThe CelebA dataset comes with a .csv file containing attributes for each image, and corresponding file names.\nThe actual image files can be found in a subfolder, where the file names match those in the .csv file.\nWe define a class to handle the loading and processing of this dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class CelebA_data_generator:\n    def __init__(self, **kwargs):\n        self.main_folder = kwargs.get(\"main_folder\", os.path.join(data_path, \"celebA\"))\n        self.images_folder = os.path.join(\n            self.main_folder, \"img_align_celeba/img_align_celeba/\"\n        )\n        self.attributes_path = os.path.join(self.main_folder, \"list_attr_celeba.csv\")\n\n        if not (os.path.exists(self.main_folder) and os.path.exists(self.attributes_path) and os.path.exists(self.images_folder)):\n            import kagglehub\n            dataset = kagglehub.dataset_download(\"jessicali9530/celeba-dataset\")\n            self.main_folder = dataset \n            self.images_folder = os.path.join(\n                self.main_folder, \"img_align_celeba/img_align_celeba/\"\n            )\n            self.attributes_path = os.path.join(self.main_folder, \"list_attr_celeba.csv\")\n        \n        self.selected_features = kwargs.get(\"selected_features\", None)\n        self.drop_features = kwargs.get(\"drop_features\", None)\n        self.features_name = []\n        self.__prepare()\n\n    def __prepare(self):\n        # Read the CSV, and only keep files matching selected features\n        self.attributes = pd.read_csv(self.attributes_path, sep=\",\")\n        for feat in self.selected_features:\n            self.attributes = self.attributes.loc[self.attributes[feat] == 1]\n        for feat in self.drop_features:\n            self.attributes = self.attributes.loc[self.attributes[feat] == -1]\n        self.attributes.drop(self.selected_features, axis=1, inplace=True)\n        self.attributes.drop(self.drop_features, axis=1, inplace=True)\n\n        # Gathering a list of real images paths\n        self.attributes.set_index(\"image_id\", inplace=True)\n        image_path = list(self.attributes.index)\n        PIC_DIR = os.path.join(self.main_folder, \"img_align_celeba\\\\img_align_celeba\\\\\")\n        image_path = [os.path.join(PIC_DIR, path) for path in image_path]\n\n        # This is now a DataFrame with the path to each image\n        self.attributes[\"path\"] = image_path\n        self.features_name = list(self.attributes.columns)[:-1]\n\n        # We remove attributes which only appear once, as they do not provide useful information\n        drop_unique = []\n\n        def helper(col):\n            n = len(pd.unique(self.attributes[col]))\n            if n == 1:\n                drop_unique.append(col)\n\n        [helper(col) for col in self.attributes.columns]\n        self.attributes.drop(drop_unique, axis=1, inplace=True)\n        # self.attributes.reset_index(drop=True, inplace=True)\n        self.num_features = self.attributes.shape[1]\n\n    def get_images(\n        self,\n        image_ids=None,\n        exclude_image_ids=None,\n        conditionned_features=None,\n        **kwargs,\n    ):\n        Nx = kwargs.get(\"Nx\", self.attributes.shape[0])  # Number of total images\n        if image_ids is None:\n            if Nx < self.attributes.shape[0]:\n                # Sample small portion of the dataset\n                random_state = kwargs.get(\"seed\", 42)\n                if conditionned_features is None:\n                    if exclude_image_ids is None:\n                        image_ids = self.attributes.sample(\n                            Nx, random_state=random_state\n                        )[\"path\"]\n                    else:\n                        image_ids = self.attributes[\"path\"].index\n                        image_ids = ~image_ids.isin(exclude_image_ids)\n                        image_ids = self.attributes.loc[image_ids]\n\n                        image_ids = image_ids.sample(Nx, random_state=random_state)[\n                            \"path\"\n                        ]\n                else:\n                    test = self.attributes.copy()\n                    for c in conditionned_features:\n                        test = self.attributes.loc[self.attributes[c] == 1]\n                    if test.shape[0] < Nx // 2:\n                        image_ids = test[\"path\"]\n                    else:\n                        image_ids = test.sample(Nx // 2, random_state=random_state)[\n                            \"path\"\n                        ]\n                    for c in conditionned_features:\n                        test = self.attributes.loc[self.attributes[c] == -1]\n                    image_ids = pd.concat(\n                        [\n                            image_ids,\n                            test.sample(Nx - len(image_ids), random_state=random_state)[\n                                \"path\"\n                            ],\n                        ]\n                    )\n            else:\n                # Get entire dataset\n                image_ids = self.attributes[\"path\"]\n\n        PIC_DIR = kwargs.get(\n            \"PIC_DIR\",\n            os.path.join(self.main_folder, \"img_align_celeba\\\\img_align_celeba\\\\\"),\n        )\n        paths_images = [os.path.join(PIC_DIR, image_id) for image_id in image_ids]\n        images = get_images_list(\n            list_pics=list(paths_images), index=image_ids.index, **kwargs\n        )\n\n        return images\n\n    def get_data(self, N=0, **kwargs):\n        images = self.get_images(**kwargs)\n        attributes = self.attributes.loc[images.index]\n        return images, images.index, attributes\n\n\ndef get_images_list(list_pics, index=None, **kwargs):\n    if isinstance(list_pics, list):\n        out = np.asarray([get_images_list(pic, **kwargs) for pic in list_pics])\n        out = np.reshape(out, [out.shape[0], -1])\n        if index is not None:\n            out = pd.DataFrame(out, index=index)\n        return out\n    output_shape = kwargs.get(\"output_shape\", None)\n    pic = skimage.io.imread(fname=list_pics)\n    if pic.dtype != float:\n        pic = pic.astype(float) / np.max(pic)\n    if output_shape is not None:\n        pic = skimage.transform.resize(\n            pic, output_shape=output_shape, anti_aliasing=True\n        )\n        if kwargs.get(\"flat\", True):\n            pic = pic.flatten()\n    # imshow(pic),\n    return pic\n\n\ndef basic_filter(x):\n    x = x.reshape([x.shape[0] // 3, 3])\n    x -= x.min(0)\n    x /= x.max(0)\n    return x.ravel()\n\n\ndef tiles(x, **kwargs):\n    SQ = kwargs.get(\"N\", int(np.sqrt(x.shape[0])))\n    tile_shape = kwargs.get(\"tile_shape\", [SQ, SQ])\n    pic_shape = kwargs[\"pic_shape\"]\n    Dz = int(len(x[0]) / (pic_shape[0] * pic_shape[1]))\n    filter = kwargs.get(\"filter\", basic_filter)\n    if filter is not None:\n        for n in range(x.shape[0]):\n            x[n] = filter(x[n])\n    if Dz > 1:\n        img = np.zeros([x.shape[0], pic_shape[0], pic_shape[1], Dz])\n    else:\n        img = np.zeros([x.shape[0], pic_shape[0], pic_shape[1], Dz])\n    for j in range(x.shape[0]):\n        pic = x[j]\n        pic = pic.reshape((pic_shape[0], pic_shape[1], Dz))\n        # imshow(pic),\n        img[j] = pic\n\n    out = np.zeros([tile_shape[0] * pic_shape[0], tile_shape[1] * pic_shape[1], Dz])\n    for j in range(tile_shape[0]):\n        for k in range(tile_shape[1]):\n            ind = j * tile_shape[1] + k\n            if ind < img.shape[0]:\n                out[\n                    j * pic_shape[0] : (j + 1) * pic_shape[0],\n                    k * pic_shape[1] : (k + 1) * pic_shape[1],\n                ] = img[ind]\n\n    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\nWe define parameters for the experiment. Input shape is the original image size.\nRescale shape is the size to which images will be resized for processing, before being flattened and used in the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "config = {\n    \"input_shape\": [218, 178],\n    \"rescale_shape\": [50, 50],\n    \"Nx\": 1000,  # Number of images to use for training\n    \"Nz\": 16,  # Numer of images to generate\n    \"seed\": 43,\n    \"main_folder\": os.path.join(data_path, \"celebA\"),\n}\n\n\ndef launch_celebA_generator(\n    kwargs=config,\n    selected_features=[\"Blond_Hair\", \"Attractive\", \"Smiling\"],\n    drop_features=[\"Male\"],\n    dimensions=[1, 2, 3, 10, 40],\n):\n    N = np.sqrt(kwargs[\"Nz\"])  # Width of the tiles\n    assert (\n        N - int(np.sqrt(kwargs[\"Nz\"])) == 0\n    ), \"Number of generated images (Nz) must be a perfect square for plotting on tiles\"\n    N = int(N)\n\n    # Load images\n    celeba = CelebA_data_generator(\n        selected_features=selected_features, drop_features=drop_features\n    )\n    x_target, images_index, images_attributes = celeba.get_data(**kwargs)\n    print(f\"Loaded {x_target.shape[0]} images\")\n\n    for d in dimensions:\n        params = kwargs.copy()\n\n        # Get latent dim\n        # We make a sampler mapping to a latent space of dimension d draw from normal distribution\n        Nz = kwargs[\"Nz\"]  # Number of images to generate\n        sampler = Sampler(x=x_target.values, latent_dim=d, iter=0, reg=0.0)\n\n        sampled_latent = np.random.normal(size=(Nz, d))\n        closest_indices = sampler.dnm(x=sampled_latent).argmin(1)\n        closest_latent = sampler.get_x()[closest_indices]\n\n        generated_pics = sampler(z=sampled_latent)  # (Nz, kwargs['input_shape'])\n        database_pics = sampler(z=closest_latent)  # (Nz, kwargs['input_shape'])\n\n        pic_generated = tiles(\n            generated_pics, pic_shape=params[\"input_shape\"], tile_shape=[N, N]\n        )\n        pic_database = tiles(\n            database_pics, pic_shape=params[\"input_shape\"], tile_shape=[N, N]\n        )\n\n        pic_name = str(kwargs[\"Nx\"]) + \"D_\" + str(d) + \".png\"\n        plt.imsave(\n            os.path.join(proj_path, \"pic_generated_N\" + pic_name),\n            pic_generated,\n            vmin=0.0,\n            vmax=1.0,\n        )\n        plt.show()\n        plt.imsave(\n            os.path.join(proj_path, \"pic_database_N\" + pic_name),\n            pic_database,\n            vmin=0.0,\n            vmax=1.0,\n        )\n        plt.show()\n        print(\"Saved\", pic_name)\n\n\ndef launch_celebA_Wasserstein_generator(\n    kwargs=config,\n    selected_features=[\"Blond_Hair\", \"Attractive\", \"Smiling\"],\n    drop_features=[\"Male\"],\n    dimensions=[1, 2, 3, 10, 40],\n):\n    N = np.sqrt(kwargs[\"Nz\"])  # Width of the tiles\n    assert (\n        N - int(np.sqrt(kwargs[\"Nz\"])) == 0\n    ), \"Number of generated images (Nz) must be a perfect square for plotting on tiles\"\n    N = int(N)\n\n    def celebA_Wasserstein_descent(pics, database_pics, latent_values, generator):\n        \"\"\"\n        This function performs a Wasserstein descent on the generated images to find the closest images in the database.\n        It uses the Sampler to generate images and find the closest ones in the database.\n        \"\"\"\n        # We compute the distance between generated and database images\n        generated_pics = generator(z=latent_values)  # (Nz, kwargs['input_shape'])\n        closest_images_indice = core.KerOp.dnm(\n            x=generated_pics, y=database_pics, distance=\"norm1\"\n        )\n        closest_images_indice = closest_images_indice.argmin(1)\n        closest_images = database_pics[closest_images_indice]\n\n        def sgn(x):\n            return math.copysign(1, x)\n\n        # diff = np.vectorize(sgn)(generated_pics - closest_images)\n        diff = generated_pics - pics\n        nablas = generator.grad(z=latent_values)\n        nablas = -np.einsum(\"ijk,ik->ij\", nablas, diff)\n\n        # nablas /= np.abs(nablas).mean(1)[:,None]\n        def error(a, b):\n            return np.linalg.norm(a - b) ** 2\n            return np.linalg.norm(a - b, 1)\n\n        error_ = error(pics, generated_pics)\n\n        def f(x):\n            latent = latent_values + x * nablas\n            out = generator(z=latent)\n            out = error(out, pics)\n            return out\n\n        count = 0\n        while count < 10:\n            a, b, c = f(0.0), f(1e-8), f(2e-8)\n            fprime = (b - a) / 1e-8\n            assert fprime <= 0.0\n            bound = -a / fprime\n            fsec = (a + c - 2 * b) / (1e-16)\n            if fsec >= 0:\n                bound = max(bound, -fprime / fsec)\n            # bound = 1./np.linalg.norm(nablas)**2\n            xmin, fval, iter, funcalls = optimize.brent(\n                f, brack=(0.0, bound), maxiter=5, full_output=True\n            )\n            if fval >= error_:\n                break\n            latent_values, error_ = latent_values + xmin * nablas, fval\n            generated_pics = generator(z=latent_values)\n            nablas = generator.grad(z=latent_values)\n            # diff = np.vectorize(sgn)(generated_pics - closest_images)\n            diff = generated_pics - pics\n            nablas = -np.einsum(\"ijk,ik->ij\", nablas, diff)\n            # nablas /= np.abs(nablas).mean(1)[:,None]\n            count = count + 1\n            pass\n\n        generated_pics = generator(z=latent_values)\n\n        return generated_pics, closest_images\n\n    # Load images\n    celeba = CelebA_data_generator(\n        selected_features=selected_features, drop_features=drop_features\n    )\n    x_target, images_index, images_attributes = celeba.get_data(**kwargs)\n    print(f\"Loaded {x_target.shape[0]} images\")\n\n    for d in dimensions:\n        params = kwargs.copy()\n\n        # Get latent dim\n        # We make a sampler mapping to a latent space of dimension d draw from normal distribution\n        Nz = kwargs[\"Nz\"]  # Number of images to generate\n        new_images = celeba.get_images(Nx=16, exclude_image_ids=images_index)\n        generator = Sampler(x=x_target.values, latent_dim=d, iter=0, reg=0.0)\n        # new_images = generator.get_fx()\n        encoder = Kernel(x=generator.get_fx(), fx=generator.get_x())\n        latent_values = encoder(new_images)\n        # latent_values = generator.get_x()[:Nz] + np.random.normal(size=(Nz, d))*.001\n        generated_pics, database_pics = celebA_Wasserstein_descent(\n            new_images, generator.get_fx(), latent_values, generator\n        )  # (Nz, kwargs['input_shape'])\n        # generated_pics = generator(latent_values)\n        # closest_images_indice = core.KerOp.dnm(x=generated_pics,y=generator.get_fx(),distance=\"norm1\")\n        # closest_images_indice = scipy_lsap(closest_images_indice)\n        # database_pics= generator.get_fx()[closest_images_indice]\n\n        pic_generated = tiles(\n            generated_pics, pic_shape=params[\"input_shape\"], tile_shape=[N, N]\n        )\n        pic_database = tiles(\n            database_pics, pic_shape=params[\"input_shape\"], tile_shape=[N, N]\n        )\n\n        pic_name = str(kwargs[\"Nx\"]) + \"D_\" + str(d) + \".png\"\n        plt.imsave(\n            os.path.join(proj_path, \"pic_generated_N\" + pic_name),\n            pic_generated,\n            vmin=0.0,\n            vmax=1.0,\n        )\n        plt.show()\n        plt.imsave(\n            os.path.join(proj_path, \"pic_database_N\" + pic_name),\n            pic_database,\n            vmin=0.0,\n            vmax=1.0,\n        )\n        plt.show()\n        print(\"Saved\", pic_name)\n\n\nif __name__ == \"__main__\":\n    # launch_celebA_generator(dimensions = [40])\n    launch_celebA_Wasserstein_generator(dimensions=[10])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}